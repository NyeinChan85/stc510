{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401a9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from time import sleep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173e32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first: initializing the webdriver for Chrome (which was saved in the same directory)\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://newyork.craigslist.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c431ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for the site to fully load\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "#getting the page_source\n",
    "page = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6217d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pursing BeautifulSoup to parse the page\n",
    "soup = BS(page, 'html.parser')\n",
    "\n",
    "# ul #id'jjji0' contains the job catagories listed on the site. using beautifulsoup to find the content (available job catagories)\n",
    "content = soup.find('ul', id='jjj0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f43e7f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# using if condition to search for all 'span' elecments to extract and saving it to a list\n",
    "if content:\n",
    "    job_catagory_list = content.find_all('span')  \n",
    "    \n",
    "    # writing out the results to a CSV file \n",
    "    with open('job_catagories_list.csv', mode='w', newline='', encoding='utf-8') as outputFile:\n",
    "        jobsCSV = csv.writer(outputFile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        jobsCSV.writerow(['Types of Jobs in New York found on Craiglist'])\n",
    "        jobsCSV.writerow(['--------------------------------------------'])\n",
    "\n",
    "        for job in job_catagory_list:\n",
    "            Name = job.text.strip()\n",
    "            jobsCSV.writerow([Name])\n",
    "\n",
    "        # printing out the message after the CSV file is successfully generated\n",
    "        print(\"CSV file generated successfully.\")\n",
    "else:\n",
    "    # if not found\n",
    "    print(\"Content not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d492ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f9f7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
